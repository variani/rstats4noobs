---
title: "Tutorial on rmr2"
author: "Andrey Ziyatdinov"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: united
    toc: true
    keep_md: true
---

```{r options, echo = F}
opts_chunk$set(fig.path = "figures/", comment = NA, results = 'markup', tidy = F, message = F, warning = F, echo = T)
```

```{r inc, echo = F, cache = FALSE}
library(plyr)
library(ggplot2)
library(gridExtra)

library(pander)
```

```{r settings, echo = F, cache = FALSE}
theme_set(theme_light())
panderOptions('table.split.table', Inf)
panderOptions('knitr.auto.asis', FALSE)
```

# About

References

* Example 1 Squares of integers & Example 2 Groups: [basic-examples.R](https://github.com/RevolutionAnalytics/rmr2/blob/master/pkg/tests/basic-examples.R)
* Example 2 Words Count: [wordcount.R](https://github.com/RevolutionAnalytics/rmr2/blob/master/pkg/tests/wordcount.R)
* Example 3 OLS
    * [linear-least-squares.R](https://github.com/RevolutionAnalytics/rmr2/blob/master/pkg/tests/linear-least-squares.R)
    * The same code with more details at [144.pdf](http://cks.univnt.ro/uploads/cks_2015_articles/index.php?dir=12_IT_in_social_sciences%2F&download=CKS+2015_IT_in_social_sciences_art.144.pdf)
* Example 4 K-means clustering
    * R code [kmeans.R](https://github.com/RevolutionAnalytics/rmr2/blob/master/pkg/tests/kmeans.R)


# Preparation

Set up Hadoop environment variables:

```{r env_hadoop}
Sys.setenv("HADOOP_CMD" = "/home/hduser/hadoop/bin/hadoop")
Sys.setenv("HADOOP_STREAMING" = "/home/hduser/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar")
```

Include the R-Hadoop libraries:

```{r inc_rhadoop, cache = FALSE}
library(rhdfs)
library(rhbase)
library(rmr2)
```

# Map-reduce Examples

## Map-reduce Example 1: Squares of integers

```{r ex1, cache = TRUE}
small.ints <- to.dfs(1:1000)

ret1 <- mapreduce(
  input = small.ints, 
  map = function(k, v) cbind(v, v^2))

out1 <- from.dfs(ret1)
```

Plot results:

```{r plot1, cache = TRUE}
df <- as.data.frame(out1$val)
names(df) <- c("v", "v2")

ggplot(df, aes(v, v2)) + geom_point()
```

## Map-reduce Example 2: Groups

Data in R:

```{r gr, cache = T}
set.seed(1)
groups <- rbinom(32, n = 50, prob = 0.4)
```

R code with `tapply` equivalent to map-reduce operation:

```{r tapply, cache = T}
tapply(groups, groups, length)
```

Send data to HDFS:

### Reduce is skipped

```{r groups_dfs, cache = TRUE}
groups_dfs <- to.dfs(groups)
```

```{r ex2_1, cache = TRUE}
ret2_1 <- mapreduce(
  input = groups_dfs, 
  map = function(k, v) keyval(v, 1))

out2_1 <- from.dfs(ret2_1)
```

Table of results (first 5 rows):

```{r tab2_1, echo = FALSE, results = 'asis'}
pander(head(as.data.frame(out2_1), 5), style = 'rmarkdown')
```

### Reduce is on

```{r ex2, cache = TRUE}
ret2_2 <- mapreduce(
  input = groups_dfs, 
  map = function(k, v) keyval(v, 1), 
  reduce = function(k, vv) keyval(k, length(vv)))

out2_2 <- from.dfs(ret2_2)
```

Table of results:

```{r tab2_2, echo = FALSE, results = 'asis'}
pander(as.data.frame(out2_2), style = 'rmarkdown')
```

## Map-reduce Example 3: Word counter

Word-count functions:

```{r fun3}
wc_map <- function(k, lines, pattern = " ") 
{
  keyval(
    unlist(strsplit(lines, pattern)), 
    1)
}

wc_reduce <- function(word, counts) 
{
  keyval(
    word, 
    sum(counts))
}
```

```{r text3, cache = T}
text <- capture.output(license())
text_dfs <- to.dfs(text)
```

```{r show_text}
text
```

```{r ex3, cache = T}
ret3 <- mapreduce(
  input = text_dfs, 
  map = wc_map, reduce = wc_reduce, combine = TRUE)
  
out3 <- from.dfs(ret3)  
```

Top 5 words:

```{r tab5, echo = FALSE, results = 'asis'}
df <- as.data.frame(out3)

ord <- order(df$val, decreasing = TRUE)
df <- df[ord, ]

rownames(df) <- NULL

pander(head(df, 5), style = 'rmarkdown')
```

## Map-reduce Example 4: OLS solution for linear model

### Learn `Reduce` function

The `+` operator doesn't work for more than 2 matrices.

```{r}
ret <- try(do.call("+", llply(1:3, function(i) matrix(i, 2, 2))))
cat(ret)
```

```{r Reduce}
# See `?Reduce` for more info.
add <- function(x) Reduce("+", x)

# input list of matrices
llply(1:2, function(i) matrix(i, 2, 2))

# pass it to `add` function
add(llply(1:2, function(i) matrix(i, 2, 2)))
```

### Learn parallel computation of t(X) * X

```{r par_multt}
# 10 observations, 4 variables
X <- matrix(1:10, 10, 4)
X

# split `X` matrix into batches by rows
X1 <- X[1:4, ]
X2 <- X[5:10, ]

# see results of computation per batch
list(t(X1) %*% X1, t(X2) %*% X2)

# sum up the results per batch
add(list(t(X1) %*% X1, t(X2) %*% X2))

# compare with `unparallel` code
t(X) %*% X
```

### Simulate data

```{r dat_ex5, cache = T}
nr <- 2e5
nc <- 10
set.seed(1)
X <- matrix(rnorm(nr * nc), ncol = nc)

X_dfs <- to.dfs(cbind(1:nrow(X), X))
y <- as.matrix(rnorm(nr))
```

### Reducer is missing

```{r ex5_1, cache = T}
ret5_1 <- mapreduce(
  input = X_dfs, 
  map = function(., Xi) {
    list(dim(Xi))
  }) 
 
out5_1 <- from.dfs(ret5_1)
```
       
```{r str_out5_1}
str(out5_1)
```

### Reducer for tXX

```{r}
ols_reduce <- function(., M) keyval(1, list(Reduce('+', M)))
```

```{r out5_2, cache = TRUE}
ret5_2 <- mapreduce(input = X_dfs,
  map = function(., Xi) {
    Xi <- Xi[,-1]
    keyval(1, list(t(Xi) %*% Xi))
  }, 
  reduce = ols_reduce,
  combine = TRUE)

out5_2 <- values(from.dfs(ret5_2))[[1]]
```

```{r}
dim(out5_2)
out5_2[1:3, 1:3]
```

### A complete OLS example

Steps:

* simulate data `X` and `y`
* put a big matrix `X` onto HDFS
* compute `tXX` and `tXy` on hadoop
* solve OLS in R


```{r ols_ex, cache = TRUE}
# simulate data
nr <- 2e3
nc <- 10
set.seed(1)
X <- matrix(rnorm(nr * nc), ncol = nc)

X_dfs <- to.dfs(cbind(1:nrow(X), X))
y <- as.matrix(rnorm(nr)) 

ols_reduce <- function(., M) keyval(1, list(Reduce('+', M)))

tXX <- values(from.dfs(mapreduce(input = X_dfs,
  map = function(., Xi) {
    Xi <- Xi[,-1]
    keyval(1, list(t(Xi) %*% Xi))
  }, 
  reduce = ols_reduce,
  combine = TRUE)))[[1]]
  
tXy <- values(from.dfs(mapreduce(input = X_dfs,
  map = function(., Xi) {
    yi <- y[Xi[,1], , drop = FALSE]
    Xi <- Xi[,-1]
    keyval(1, list(t(Xi) %*% yi))
  }, 
  reduce = ols_reduce,
  combine = TRUE)))[[1]]  
```

```{r beta_hadoop, cache = TRUE}
beta_hadoop <- solve(tXX, tXy)
```

```{r beta_R, cache = TRUE}
beta_R <- solve(t(X) %*% X, t(X) %*% y)
```

Two vectors are identical:

```{r}
sqrt(sum((beta_hadoop - beta_R)^2))
```

```{r, echo = FALSE, results = 'asis'}
pander(data.frame(beta_R = beta_R, beta_hadoop = beta_hadoop), style = 'rmarkdown')
```

## Map-reduce Example 5 K-means Clustering

### Simulate data in R

```{r sim_kmeans, cache = T}
set.seed(1)
P <- do.call(rbind, rep(list(matrix(rnorm(10, sd = 10), ncol = 2)), 20)) + 
  matrix(rnorm(200), ncol = 2)
```

```{r plot_simdat, cache = T}
ggplot(as.data.frame(P), aes(V1, V2)) + geom_point()
```

### Distance function

```{r kmeans_dist}
kmeans_dist <- function(C, P) 
{
  apply(C, 1, function(x) rowSums((P - x)^2))
}
```

### Map-Reduce functions

```{r kmeans_mr}
kmeans_mapper <- function(., P) 
{
  nearest <- {
    if(is.null(C)) {
      sample(1:num.clusters, nrow(P), replace = TRUE)
    } else {
      D <- kmeans_dist(C, P)
      max.col(-D)
    }
  }
  
  if(!(combine || in.memory.combine)) {
    keyval(nearest, P)
  } else {
    keyval(nearest, cbind(1, P))
  }
}

kmeans_reducer <- {
  if(!(combine || in.memory.combine)) {
    function(., P) t(as.matrix(apply(P, 2, mean)))
  } else {
    function(k, P) keyval(k, t(as.matrix(apply(P, 2, sum))))
  }
}
```

### K-means clustering 1: 12 clusters

```{r kmeans_1, cache = TRUE}
num.clusters <- 12
num.iter <- 5
combine <- FALSE
in.memory.combine <- FALSE

P_dfs <- to.dfs(P)
      
C <- NULL
for(i in 1:num.iter ) {
  out <- mapreduce(input = P_dfs, map = kmeans_mapper, reduce = kmeans_reducer)
  C <- values(from.dfs(out))
  
  if(combine || in.memory.combine) {
    C <- C[, -1]/C[, 1]
  }
}  

C1 <- C
```  

```{r plot_kmeans1}
ggplot(as.data.frame(P), aes(V1, V2)) + geom_point() + geom_point(aes(V1, V2), data = as.data.frame(C1), color = "red")
```

### K-means clustering 2: 5 clusters

```{r kmeans_2, cache = TRUE}
num.clusters <- 5
num.iter <- 5
combine <- FALSE
in.memory.combine <- FALSE

P_dfs <- to.dfs(P)
      
C <- NULL
for(i in 1:num.iter ) {
  out <- mapreduce(input = P_dfs, map = kmeans_mapper, reduce = kmeans_reducer)
  C <- values(from.dfs(out))
  
  if(combine || in.memory.combine) {
    C <- C[, -1]/C[, 1]
  }
}  

C2 <- C
```  

```{r plot_kmeans2}
ggplot(as.data.frame(P), aes(V1, V2)) + geom_point() + geom_point(aes(V1, V2), data = as.data.frame(C2), color = "red")
```
